# @package training
defaults:
  - /training/default

epochs: 500
num_workers: 4
batch_size: 8

optim:
  base_lr: 0.001
  optimizer:
    class: Adam
    params:
      lr: ${training.optim.base_lr} # The path is cut from training
      weight_decay: 0
  bn_scheduler:
    bn_policy: "step_decay"
    params:
      bn_momentum: 0.1
      bn_decay: 0.5
      decay_step: 20
      bn_clip: 1e-2

wandb:
  project: panoptic
  notes: "Minkowski baseline"
  name: "PointGroup"
  config:
    grid_size: ${data.grid_size}
