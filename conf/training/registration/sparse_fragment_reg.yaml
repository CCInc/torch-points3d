# @package training
defaults:
  - /training/default
  - override optim/optimizer: SGD

epochs: 200
num_workers: 6
batch_size: 4

optim:
  base_lr: 1e-1
  optimizer:
    momentum: 0.8
    weight_decay: 1e-4
  lr_scheduler:
    class: ExponentialLR
    params:
      gamma: 0.99
  bn_scheduler: {}

wandb:
  project: registration
