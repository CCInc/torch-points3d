# @package training
defaults:
  - /training/default

epochs: 550
num_workers: 7
batch_size: 8
precompute_multi_scale: True # Compute multiscate features on cpu for faster training / inference

optim:
  base_lr: 0.01
  grad_clip: 100
  optimizer:
    class: SGD
    params:
      momentum: 0.98
      lr: ${training.optim.base_lr}
      weight_decay: 1e-3
  bn_scheduler:
    bn_policy: "step_decay"
    params:
      bn_momentum: 0.02
      bn_decay: 0.9
      decay_step: 1000
      bn_clip: 1e-2

wandb:
  project: registration
